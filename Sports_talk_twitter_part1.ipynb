{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Men and Women Sportscasters Talk about Sports Differently?\n",
    "Awhile ago I was reading a few articles on women's sports and analysis thereof and ran across [this post][1]. I couldn't agree more that there is a serious lack of data on women's sports and thought I would try to address that to the extent that I could. As the article points out, there are some cool grassroots [efforts][2] and I'd like to contribute to these at some point, though moving to Kenya kind of put that on hold. In the meantime though, I thought I could contribute to the lack of data on women's sports by looking at whether we talk about them differently. Having recently been reading [Unusual Efforts][3], I found there writing to be very interesting because so much of it focused on how the writers relate to soccer (though there is certainly quality analysis as well). Now, clearly the point of the site is different than say, [statsbomb][4] or [whoscored][5], but it made me think that maybe journalists covering sports talked about women's and men's sports differently and that maybe women and men journalists used different verbiage. \n",
    "\n",
    "I brought this idea to Adam and he agreed that it would be interesting to check out these potential differences - and he's pretty interested in text-mining. So this project will be analyzing the twitter feeds for various sports journalists. Adam and I aren't completely sure on what type of analysis we'll do, but the goal is to make some cool visualizations and to see if there are any differences. Of course, this may be a pretty shallow analysis given that (1) we are focusing on a narrow subset of the population who are in the public eye and thus their behavior may all tend towards some average and (2) this is twitter rather than looking at journal pieces or actual commentary so the language used and character constraints may be too shallow to draw out differences. \n",
    "\n",
    "## This post is about getting the data\n",
    "Well for any analysis you need data, so this post is all about grabbing the twitter data using [tweepy][6]. There's a couple of different programs to use to grab the data, Adam and I just landed on tweepy cause we saw a [good blog post][7] using it, and then it turned out to have the get_all_tweets() function which was pretty great. Overall, grabbing the data was much easier than my NBA scraping experience.\n",
    "\n",
    "[1]: https://howwegettonext.com/women-are-being-left-behind-by-the-sports-data-revolution-db87cdb65f57#.2ws69oxq4\n",
    "[2]: https://wosostats.wordpress.com/\n",
    "[3]: http://www.unusualefforts.com/\n",
    "[4]: https://statsbomb.com\n",
    "[5]: https://www.whoscored.com/\n",
    "[6]: http://docs.tweepy.org/en/v3.5.0/cursor_tutorial.html\n",
    "[7]: https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Necessary imports for getting all this data\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import sqlite3\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL in Python\n",
    "I've been taking some online courses through Coursera to learn more Python data science stuff and one of the projects was to write a program that mined a huge text file and to then populate a SQLite table. Quite a bit of the work in the course recently has focused on using relational databases in SQL to save on space and the integration between Python and SQL. Having not used SQL really at all prior to the course, seeing how clean SQL code is even compared to something like Stata is pretty striking. Anyway, I thought I'd try out writing this data into a SQL database just to do it myself, thus the code below. Adam prefers just to run the analysis through a csv/pandas df because of issues with his computer. Below is me just setting up the database and populating one table with the twitter handles we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1263ac260>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a sql table of twitter handles we are interested in\n",
    "conn = sqlite3.connect('Dropbox/Python/jupyter-blog/content/Twitter_soccer/twitter_sports.sqlite')\n",
    "conn.text_factory = str\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.executescript(\"\"\"\n",
    "DROP TABLE IF EXISTS User;\n",
    "DROP TABLE IF EXISTS Tweet_sports;\n",
    "\n",
    "CREATE TABLE User (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    Name TEXT UNIQUE,\n",
    "    Handle   TEXT UNIQUE,\n",
    "    Sex TEXT\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1263ac260>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.executescript('''\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"The Equalizer\", \"EqualizerSoccer\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Alexi Lalas\", \"AlexiLalas\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Eric Wynalda\", \"EricWynalda\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Taylor Twellman\", \"TaylorTwellman\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Kate Markgraf\", \"katemarkgraf\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Julie Foudy\", \"JulieFoudy\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Brad Friedel\", \"friedel_b\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Julie Stewart-Binks\", \"JSB_FOX\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Kyle Martino\", \"kylemartino\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Brandi Chastain\", \"brandichastain\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Aly Wagner\", \"alywagner\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Abby Wambach\", \"AbbyWambach\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Kate Abdo\", \"kate_abdo\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Gabriel Marcotti\", \"Marcotti\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Grant Wahl\", \"GrantWahl\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Maximilano Bretos\", \"mbretosESPN\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Rob Stone\", \"RobStoneONFOX\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Warren Barton\", \"warrenbarton2\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Arlo White\", \"arlowhite\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Alejandro Moreno\", \"AleMorenoESPN\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Robbie Mustoe\", \"robbiemustoe\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Steve Bower\", \"SteveBowercomm\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Robbie Earle & Robbie Mustoe\", \"The2RobbiesNBC\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Keith Costigan\", \"KeithCostigan\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Cat Whitehilll\", \"catwhitehill4\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Bob Ley\", \"BobLeyESPN\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Tony DiCicco\", \"tonysocc\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Mark Jackson\", \"MarkJackson13\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Hannah Storm\", \"HannahStormESPN\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Doris Burke\", \"heydb\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Michael Smith\", \"michaelsmith\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Jemele Hill\", \"jemelehill\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Jalen Rose\", \"JalenRose\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Sage Steele\", \"sagesteele\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Michelle Beadle\", \"MichelleDBeadle\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Tracy McGrady\", \"Real_T_Mac\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"LaChina Robinson\", \"LaChinaRobinson\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Stephen Bardo\", \"stephenbardo\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Lindsay Czarniak\", \"lindsayczarniak\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Mark Jones\", \"MarkJonesESPN\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Holly Rowe\", \"sportsiren\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Heather Cox\", \"HeatherCoxNBC\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Marc Kestecher\", \"marckestecher\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Rebecca Lobo\", \"RebeccaLobo\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Gene Wojciechowski\", \"GenoEspn\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Dave Pasch\", \"DavePasch\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Scott van Pelt\", \"notthefakeSVP\", \"M\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Adriana Monsalve\", \"AdrianaMonsalve\", \"F\");\n",
    "INSERT INTO User (Name, Handle, Sex) VALUES (\"Antonietta Collins\", \"AntoniettaESPN\", \"F\");\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list to use later\n",
    "From the database above, I can create a list of the twitter handles and the sex of the twitter user to use in the get_all_tweets function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = cur.execute('''SELECT Handle, Sex FROM User''')\n",
    "a_list = result.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The call returns a list of tuples,\n",
    "Which is pretty nice cause the tuple can be iterated over easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EqualizerSoccer', 'F'),\n",
       " ('AlexiLalas', 'M'),\n",
       " ('EricWynalda', 'M'),\n",
       " ('TaylorTwellman', 'M'),\n",
       " ('katemarkgraf', 'F'),\n",
       " ('JulieFoudy', 'F'),\n",
       " ('friedel_b', 'M'),\n",
       " ('JSB_FOX', 'F'),\n",
       " ('kylemartino', 'M'),\n",
       " ('brandichastain', 'F'),\n",
       " ('alywagner', 'F'),\n",
       " ('AbbyWambach', 'F'),\n",
       " ('kate_abdo', 'F'),\n",
       " ('Marcotti', 'M'),\n",
       " ('GrantWahl', 'M'),\n",
       " ('mbretosESPN', 'M'),\n",
       " ('RobStoneONFOX', 'M'),\n",
       " ('warrenbarton2', 'M'),\n",
       " ('arlowhite', 'M'),\n",
       " ('AleMorenoESPN', 'M'),\n",
       " ('robbiemustoe', 'M'),\n",
       " ('SteveBowercomm', 'M'),\n",
       " ('The2RobbiesNBC', 'M'),\n",
       " ('KeithCostigan', 'M'),\n",
       " ('catwhitehill4', 'F'),\n",
       " ('BobLeyESPN', 'M'),\n",
       " ('tonysocc', 'M'),\n",
       " ('MarkJackson13', 'M'),\n",
       " ('HannahStormESPN', 'F'),\n",
       " ('heydb', 'F'),\n",
       " ('michaelsmith', 'M'),\n",
       " ('jemelehill', 'F'),\n",
       " ('JalenRose', 'M'),\n",
       " ('sagesteele', 'F'),\n",
       " ('MichelleDBeadle', 'F'),\n",
       " ('Real_T_Mac', 'M'),\n",
       " ('LaChinaRobinson', 'F'),\n",
       " ('stephenbardo', 'M'),\n",
       " ('lindsayczarniak', 'F'),\n",
       " ('MarkJonesESPN', 'M'),\n",
       " ('sportsiren', 'F'),\n",
       " ('HeatherCoxNBC', 'F'),\n",
       " ('marckestecher', 'M'),\n",
       " ('RebeccaLobo', 'F'),\n",
       " ('GenoEspn', 'M'),\n",
       " ('DavePasch', 'M'),\n",
       " ('notthefakeSVP', 'M'),\n",
       " ('AdrianaMonsalve', 'F'),\n",
       " ('AntoniettaESPN', 'F')]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-lists to deal with time out issues\n",
    "In running the function to grab the tweets, I got timed out through a break in the connection to twitter which is apparently common when you're running quite a bit of code, even if you're observing twitter's rate limits. I left the error in the code below to show it, but that's why I've created this sublists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_list = a_list[17:32]\n",
    "c_list = a_list[32:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unneeded for some reason now?\n",
    "Originally, when I pulled the twitter handles and sex from the SQL table it returned a list of tuples but where the tuples were in the form (u'handle', u'sex'). To deal with that, I changed the tuples to a list first, then used a short regular expression below to extract what I wanted before flipping it back to a tuple. Not sure why, but at some point I ran the code and it just returned the tuples without the unneeded u'' stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(0,len(a_list)):\n",
    "    handle = re.findall(\"\\(u'(.*)', u'(.*)'\\)\", a_list[i])\n",
    "    print handle\n",
    "    names.append(handle)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rorypulvino\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you to [yanofsky][1]\n",
    "Adam and I started out by trying to write our own scripts to grab the tweets we wanted. We wanted initially to grab tweets from specific periods in time, such as during the women's world cup or the Olympics when sportscasters were more likely to be tweeting about both men and women's sports. Unfortunately, twitter doesn't let you do this. But because this is where we started, we didn't look for someone else's function in a very effective way at first. We had some initial success as well and tweepy is pretty easy to use, but after about a day of playing around I decided it'd be better to just search out someone that had likely done this in a cleaner fashion than I or Adam was likely to ever do. I quickly found yanofsky's get_all_tweets function, downloaded the script and started modifying it for my needs. Below is just me loading it up and then running it on my own twitter handle to show how it works.\n",
    "[1]: https://gist.github.com/yanofsky/5436496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting tweet grab function\n",
    "% run Dropbox/Python/jupyter-blog/content/tweet_dumper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 539173446182526976\n",
      "...10 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"rorypul\", \"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altering the function\n",
    "I altered the get_all_tweets() function in a number of ways that I've posted to a GitHubGist of the code. Mainly, I altered it to grab favorite count, retweet count, hashtags and user mentions. Getting hashtags and user mentions was more difficult and involved writing in a number of ugly try-except statements into the function since the hashtags and user mentions are nested keys inside a list of dictionary's inside another dictionary. Because of this, when a tweet did not have a hashtag or a user mention the function blew up with an index error since the thing didn't exist, thus the try-except statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter_Handle</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Text</th>\n",
       "      <th>Favorite_count</th>\n",
       "      <th>Retweet_count</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>User_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>730921414178439169</td>\n",
       "      <td>2016-05-13 00:43:39</td>\n",
       "      <td>RT @poverty_action: New study in Science: \"Pos...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poverty_action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>726062391134281728</td>\n",
       "      <td>2016-04-29 14:55:38</td>\n",
       "      <td>RT @landportal: Good Read: Reshaping the Debat...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>landrights</td>\n",
       "      <td>landportal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>639474464388988929</td>\n",
       "      <td>2015-09-03 16:26:07</td>\n",
       "      <td>Mobile technology for non-judicial grievance m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>628239016417185792</td>\n",
       "      <td>2015-08-03 16:20:28</td>\n",
       "      <td>The Land Battle: 15 Organizations Defending La...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>571787355134291969</td>\n",
       "      <td>2015-02-28 21:41:43</td>\n",
       "      <td>#removeterranceburk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>removeterranceburk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>571787241665781760</td>\n",
       "      <td>2015-02-28 21:41:16</td>\n",
       "      <td>RT @IEDPBrazil: When in Brazil, #GoBlue! Thank...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>GoBlue</td>\n",
       "      <td>IEDPBrazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>571782596335677441</td>\n",
       "      <td>2015-02-28 21:22:48</td>\n",
       "      <td>RT @IEDPBrazil: A gente acaba de chegar em Bra...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IEDPBrazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>539889222996348928</td>\n",
       "      <td>2014-12-02 21:09:56</td>\n",
       "      <td>I just made a donation to U-M for #GivingBlued...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>GivingBlueday</td>\n",
       "      <td>IEDPBrazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>539782469382574081</td>\n",
       "      <td>2014-12-02 14:05:44</td>\n",
       "      <td>IPSA should receive an extra $1,000 today for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GivingBlueday</td>\n",
       "      <td>UMichStudents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rorypul</td>\n",
       "      <td>M</td>\n",
       "      <td>539173446182526977</td>\n",
       "      <td>2014-11-30 21:45:41</td>\n",
       "      <td>@IEDPBrazil http://t.co/5QZNk7ra65 Brazil's ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IEDPBrazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Twitter_Handle Sex            Tweet_id           Created_at  \\\n",
       "0        rorypul   M  730921414178439169  2016-05-13 00:43:39   \n",
       "1        rorypul   M  726062391134281728  2016-04-29 14:55:38   \n",
       "2        rorypul   M  639474464388988929  2015-09-03 16:26:07   \n",
       "3        rorypul   M  628239016417185792  2015-08-03 16:20:28   \n",
       "4        rorypul   M  571787355134291969  2015-02-28 21:41:43   \n",
       "5        rorypul   M  571787241665781760  2015-02-28 21:41:16   \n",
       "6        rorypul   M  571782596335677441  2015-02-28 21:22:48   \n",
       "7        rorypul   M  539889222996348928  2014-12-02 21:09:56   \n",
       "8        rorypul   M  539782469382574081  2014-12-02 14:05:44   \n",
       "9        rorypul   M  539173446182526977  2014-11-30 21:45:41   \n",
       "\n",
       "                                                Text  Favorite_count  \\\n",
       "0  RT @poverty_action: New study in Science: \"Pos...               0   \n",
       "1  RT @landportal: Good Read: Reshaping the Debat...               0   \n",
       "2  Mobile technology for non-judicial grievance m...               0   \n",
       "3  The Land Battle: 15 Organizations Defending La...               0   \n",
       "4                                #removeterranceburk               0   \n",
       "5  RT @IEDPBrazil: When in Brazil, #GoBlue! Thank...               0   \n",
       "6  RT @IEDPBrazil: A gente acaba de chegar em Bra...               0   \n",
       "7  I just made a donation to U-M for #GivingBlued...               2   \n",
       "8  IPSA should receive an extra $1,000 today for ...               1   \n",
       "9  @IEDPBrazil http://t.co/5QZNk7ra65 Brazil's ne...               0   \n",
       "\n",
       "   Retweet_count            Hashtags   User_mentions  \n",
       "0             12                 NaN  poverty_action  \n",
       "1             14          landrights      landportal  \n",
       "2              0                 NaN             NaN  \n",
       "3              0                 NaN             NaN  \n",
       "4              1  removeterranceburk             NaN  \n",
       "5              6              GoBlue      IEDPBrazil  \n",
       "6              2                 NaN      IEDPBrazil  \n",
       "7              2       GivingBlueday      IEDPBrazil  \n",
       "8              1       GivingBlueday   UMichStudents  \n",
       "9              1                 NaN      IEDPBrazil  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df = df.append(pd.read_csv('rorypul_tweets.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error: 'ascii' codec can't encode character u'\\xf9' in position 1\n",
    "The first time I tried to run the loop below, I got this error, which seemed way over my head. Luckily, since I had been working with writing to the SQL table recently, I had been running across ascii and utf-8 errors, so understood this related to the code of the entries. Fixing it was not so easy though. At first I tried to just quickly encode all outtweets array in the get_all_tweets function as utf-8, but kept running into an AttributeError: 'list' object has not attribute 'encode'. This kind of infuriated me since most of the answers I ran across on stackoverflow made it seem easy to just coerce a list to utf-8 using .encode('utf-8'). After spending 20 minutes pointlessly trying different iterations of the encode, I went to problem solving using try-except statements to look at where the error was occurring since it didn't occur for the first few twitter handles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-21abd091c1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mget_all_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s_tweets.csv'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rorypulvino/Dropbox/Python/jupyter-blog/content/tweet_dumper.py\u001b[0m in \u001b[0;36mget_all_tweets\u001b[0;34m(screen_name, sex)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m#all subsiquent requests use the max_id param to prevent duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mnew_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moldest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m#save most recent tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rorypulvino/anaconda2/lib/python2.7/site-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;31m# Set pagination mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rorypulvino/anaconda2/lib/python2.7/site-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m                                                 proxies=self.api.proxy)\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to send request: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0mrem_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x-rate-limit-remaining'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrem_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepError\u001b[0m: Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out."
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for (name, sex) in a_list:\n",
    "    get_all_tweets(name, sex)\n",
    "    df = df.append(pd.read_csv('%s_tweets.csv' % name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "for (name, sex) in b_list:\n",
    "    get_all_tweets(name, sex)\n",
    "    df = df.append(pd.read_csv('%s_tweets.csv' % name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "for (name, sex) in c_list:\n",
    "    get_all_tweets(name, sex)\n",
    "    df = df.append(pd.read_csv('%s_tweets.csv' % name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter_Handle</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Text</th>\n",
       "      <th>Favorite_count</th>\n",
       "      <th>Retweet_count</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>User_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EqualizerSoccer</td>\n",
       "      <td>F</td>\n",
       "      <td>795463504266481665</td>\n",
       "      <td>2016-11-07 03:10:53</td>\n",
       "      <td>.@GopherSoccer wins first Big 10 Tournament ti...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GopherSoccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EqualizerSoccer</td>\n",
       "      <td>F</td>\n",
       "      <td>795432981963874304</td>\n",
       "      <td>2016-11-07 01:09:35</td>\n",
       "      <td>The #NCAA tournament selection show is tomorro...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>NCAA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EqualizerSoccer</td>\n",
       "      <td>F</td>\n",
       "      <td>795427018062106624</td>\n",
       "      <td>2016-11-07 00:45:54</td>\n",
       "      <td>RT @GatorsSoccer: That's using your head!\\n\\nH...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GatorsSoccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EqualizerSoccer</td>\n",
       "      <td>F</td>\n",
       "      <td>795413198606389249</td>\n",
       "      <td>2016-11-06 23:50:59</td>\n",
       "      <td>.@GatorsSoccer defeated @RazorbackSoccer 2-1 i...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>SECChampionship</td>\n",
       "      <td>GatorsSoccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EqualizerSoccer</td>\n",
       "      <td>F</td>\n",
       "      <td>795410719965609988</td>\n",
       "      <td>2016-11-06 23:41:08</td>\n",
       "      <td>RT @GatorsSoccer: Here's a look at #Gators ope...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Gators</td>\n",
       "      <td>GatorsSoccer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Twitter_Handle Sex            Tweet_id           Created_at  \\\n",
       "0  EqualizerSoccer   F  795463504266481665  2016-11-07 03:10:53   \n",
       "1  EqualizerSoccer   F  795432981963874304  2016-11-07 01:09:35   \n",
       "2  EqualizerSoccer   F  795427018062106624  2016-11-07 00:45:54   \n",
       "3  EqualizerSoccer   F  795413198606389249  2016-11-06 23:50:59   \n",
       "4  EqualizerSoccer   F  795410719965609988  2016-11-06 23:41:08   \n",
       "\n",
       "                                                Text  Favorite_count  \\\n",
       "0  .@GopherSoccer wins first Big 10 Tournament ti...              19   \n",
       "1  The #NCAA tournament selection show is tomorro...              15   \n",
       "2  RT @GatorsSoccer: That's using your head!\\n\\nH...               0   \n",
       "3  .@GatorsSoccer defeated @RazorbackSoccer 2-1 i...              15   \n",
       "4  RT @GatorsSoccer: Here's a look at #Gators ope...               0   \n",
       "\n",
       "   Retweet_count         Hashtags User_mentions  \n",
       "0              1              NaN  GopherSoccer  \n",
       "1              6             NCAA           NaN  \n",
       "2             23              NaN  GatorsSoccer  \n",
       "3              3  SECChampionship  GatorsSoccer  \n",
       "4             11           Gators  GatorsSoccer  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter_Handle</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Text</th>\n",
       "      <th>Favorite_count</th>\n",
       "      <th>Retweet_count</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>User_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>AntoniettaESPN</td>\n",
       "      <td>F</td>\n",
       "      <td>789070332191731712</td>\n",
       "      <td>2016-10-20 11:46:42</td>\n",
       "      <td>ICYMI: #Messi leads the #UCL w/ 6 goals this s...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Messi</td>\n",
       "      <td>Cristiano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>AntoniettaESPN</td>\n",
       "      <td>F</td>\n",
       "      <td>789060136664985600</td>\n",
       "      <td>2016-10-20 11:06:11</td>\n",
       "      <td>What we learned: Indians pitch way into WS, Cu...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dschoenfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>AntoniettaESPN</td>\n",
       "      <td>F</td>\n",
       "      <td>789060071263199240</td>\n",
       "      <td>2016-10-20 11:05:55</td>\n",
       "      <td>RT @jaysonst: Dave Roberts says one more time ...</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jaysonst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>AntoniettaESPN</td>\n",
       "      <td>F</td>\n",
       "      <td>788931024524873732</td>\n",
       "      <td>2016-10-20 02:33:08</td>\n",
       "      <td>I can only imagine what he is thinking. 😬 htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>AntoniettaESPN</td>\n",
       "      <td>F</td>\n",
       "      <td>788912540139094016</td>\n",
       "      <td>2016-10-20 01:19:41</td>\n",
       "      <td>@RyanRosenblatt maybe at times switch it up wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RyanRosenblatt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Twitter_Handle Sex            Tweet_id           Created_at  \\\n",
       "271  AntoniettaESPN   F  789070332191731712  2016-10-20 11:46:42   \n",
       "272  AntoniettaESPN   F  789060136664985600  2016-10-20 11:06:11   \n",
       "273  AntoniettaESPN   F  789060071263199240  2016-10-20 11:05:55   \n",
       "274  AntoniettaESPN   F  788931024524873732  2016-10-20 02:33:08   \n",
       "275  AntoniettaESPN   F  788912540139094016  2016-10-20 01:19:41   \n",
       "\n",
       "                                                  Text  Favorite_count  \\\n",
       "271  ICYMI: #Messi leads the #UCL w/ 6 goals this s...               2   \n",
       "272  What we learned: Indians pitch way into WS, Cu...               2   \n",
       "273  RT @jaysonst: Dave Roberts says one more time ...               0   \n",
       "274  I can only imagine what he is thinking. 😬 htt...               1   \n",
       "275  @RyanRosenblatt maybe at times switch it up wi...               0   \n",
       "\n",
       "     Retweet_count Hashtags   User_mentions  \n",
       "271              1    Messi       Cristiano  \n",
       "272              2      NaN    dschoenfield  \n",
       "273             43      NaN        jaysonst  \n",
       "274              0      NaN             NaN  \n",
       "275              0      NaN  RyanRosenblatt  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to make sure I got all the twitter handles into the df\n",
    "len(pd.unique(df.Twitter_Handle.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Got 'em all\n",
    "The length of the list of unique twitter handles matches the length of my original list, a_list, so I know I got everyone's feed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rorypulvino\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rorypulvino/Dropbox (Personal)/Python/jupyter-blog/content/Twitter_soccer\n"
     ]
    }
   ],
   "source": [
    "cd Dropbox/Python/jupyter-blog/content/Twitter_soccer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Tweets_sports.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to a SQL table from a df is very easy\n",
    "The to_sql command makes writing the df to a SQLite table very easy and saves on having to write out execute commands to insert variables into the table and having to commit constantly. The 'Created_at' column causes problems because of it's type as well (or at least when I was "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Created_at'] = pd.to_datetime(df['Created_at'], errors='coerce')\n",
    "df.to_sql(name='Tweet_sports', con=conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial attempts before discovering get_all_tweets()\n",
    "When Adam and I started working on this project, we had different ideas of how to grab the tweets, so below is our first attempts at making our own function to grab tweets using tweepy. The first is Adam's, he preferred to dump everything into a pandas DataFrame since something is wrong with his computer (I think that's the reason he gave). I thought it made more sense to put everything into a SQL db, in part because I wanted to experiment more with SQL in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################## Works to create df with columns for each dictionary key, but only gives last 20 tweets for some reason ###########\n",
    "x = api.user_timeline('alexilalas')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in x:\n",
    "   a = json.dumps(i._json)\n",
    "   b = pd.read_json(a)\n",
    "   df = df.append(b.ix[0] )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab tweets and dump them into SQLite tables\n",
    "for status in tweepy.Cursor(api.user_timeline, id = \"alexilalas\").items(1):\n",
    "    a = json.dumps(status._json)\n",
    "    try: js = json.loads(str(a))\n",
    "    except: js = None\n",
    "    tweet = js[\"text\"]\n",
    "    cur.execute('''INSERT INTO `Tweet_sports` (Tweet) \n",
    "                    VALUES ( ? )''', ( tweet, ) )\n",
    "\n",
    "    # Grabs id numbers based on twitter handle\n",
    "    handle = \"alexilalas\"\n",
    "    cur.execute('SELECT id FROM User WHERE id = ? ', (handle, ))\n",
    "    user_id = cur.fetchone()[0]\n",
    "    \n",
    "    # Links id number from User table to user_id in Tweet_sports table\n",
    "    cur.execute('''INSERT INTO `Tweet_sports` (user_id) \n",
    "                    VALUES ( ? )''', ( user_id, ) )\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
